{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Couple of things this script cover \n",
    " - read the data\n",
    " - down sampling\n",
    " - create new variables\n",
    " - basic missing value preparations\n",
    " - find meaningful features with random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialisation and read the data\n",
    "# https://www.dataquest.io/blog/kaggle-tutorial/\n",
    "import os \n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "os.chdir('/Users/jpmallette/Desktop/kaggle_expedia/')\n",
    "\n",
    "destinations = pd.read_csv(\"destinations.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create some variables useful for downsampling \n",
    "train[\"date_time\"] = pd.to_datetime(train[\"date_time\"])\n",
    "train[\"year\"] = train[\"date_time\"].dt.year\n",
    "train[\"month\"] = train[\"date_time\"].dt.month\n",
    "\n",
    "# draw sampling base on the number of user\n",
    "def draw_sample(df,row):\n",
    "\n",
    "    unique_users = train.user_id.unique()\n",
    "\n",
    "    sel_user_ids = [unique_users[i] for i in sorted(random.sample(range(len(unique_users)), row)) ]\n",
    "    sel_train = train[train.user_id.isin(sel_user_ids)]\n",
    "\n",
    "    sample_train = sel_train[((sel_train.year == 2013) | ((sel_train.year == 2014) & (sel_train.month < 8)))]\n",
    "    sample_test = sel_train[((sel_train.year == 2014) & (sel_train.month >= 8))]\n",
    "\n",
    "    # remove click events\n",
    "    sample_test = sample_test[sample_test.is_booking == True]\n",
    "    \n",
    "    # return the data\n",
    "    return sample_train,sample_test\n",
    "\n",
    "# draw the sample\n",
    "sample_train, sample_test = draw_sample(train,10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Create new variables \n",
    "  - related to the number of people\n",
    "  - PCA reduction with destination \n",
    "  - adding new date variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>couple</th>\n",
       "      <td>96298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>32450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <td>24245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monoparental_with_kids</th>\n",
       "      <td>6560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single</th>\n",
       "      <td>34183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count\n",
       "family                       \n",
       "couple                  96298\n",
       "family                  32450\n",
       "group                   24245\n",
       "monoparental_with_kids   6560\n",
       "single                  34183"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of people in person in the bookin\n",
    "sample_train[\"nb_person\"] =  sample_train['srch_adults_cnt'] + sample_train['srch_children_cnt']\n",
    "\n",
    "# family variables\n",
    "sample_train['family'] = 'group'\n",
    "\n",
    "sample_train.ix[(sample_train.srch_adults_cnt == 1) & \n",
    "                (sample_train.srch_children_cnt == 0),'family'] = 'single'\n",
    "\n",
    "sample_train.ix[(sample_train.srch_adults_cnt == 1) & \n",
    "                (sample_train.srch_children_cnt > 0),'family'] = 'monoparental_with_kids'\n",
    "\n",
    "sample_train.ix[(sample_train.srch_adults_cnt == 2) & \n",
    "                (sample_train.srch_children_cnt == 0),'family'] = 'couple'\n",
    "\n",
    "sample_train.ix[(sample_train.srch_adults_cnt == 2) & \n",
    "                (sample_train.srch_children_cnt > 0),'family'] = 'family'\n",
    "\n",
    "sample_train.ix[(sample_train.srch_adults_cnt > 2) & \n",
    "                (sample_train.srch_children_cnt > 4),'family'] = 'group'\n",
    "\n",
    "# Explore categorisation\n",
    "sample_train.groupby(['family'])['family'].agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PCA and date variables\n",
    "pca = PCA(n_components=3)\n",
    "dest_small = pca.fit_transform(destinations[[\"d{0}\".format(i + 1) for i in range(149)]])\n",
    "dest_small = pd.DataFrame(dest_small)\n",
    "dest_small[\"srch_destination_id\"] = destinations[\"srch_destination_id\"]\n",
    "\n",
    "# date variables + PCA features\n",
    "def calc_fast_features(df):\n",
    "    \n",
    "# for preventions purposes and making sure the code will work\n",
    "    df[\"date_time\"] = pd.to_datetime(df[\"date_time\"])\n",
    "    df[\"srch_ci\"] = pd.to_datetime(df[\"srch_ci\"], format='%Y-%m-%d', errors=\"coerce\")\n",
    "    df[\"srch_co\"] = pd.to_datetime(df[\"srch_co\"], format='%Y-%m-%d', errors=\"coerce\")\n",
    "    \n",
    "# .dt only extract property of object not the data \n",
    "# getattr enable to extract the property (ex : minutes) from the date format \n",
    "# props will result in a dataframe with 6 column time data related of the date_time column.\n",
    "# props act like the base dataframe\n",
    "    props = {}\n",
    "    for prop in [\"month\", \"day\", \"hour\", \"minute\", \"dayofweek\", \"quarter\"]:\n",
    "        props[prop] = getattr(df[\"date_time\"].dt, prop)\n",
    "    \n",
    "# add all the columns in the props dataframe except timestamp column define in not in\n",
    "    carryover = [p for p in df.columns if p not in [\"date_time\", \"srch_ci\", \"srch_co\"]]\n",
    "    for prop in carryover:\n",
    "        props[prop] = df[prop]\n",
    "    \n",
    "# ad time columns related to srch_ci and srch_co\n",
    "    date_props = [\"month\", \"day\", \"dayofweek\", \"quarter\"]\n",
    "    for prop in date_props:\n",
    "        props[\"ci_{0}\".format(prop)] = getattr(df[\"srch_ci\"].dt, prop)\n",
    "        props[\"co_{0}\".format(prop)] = getattr(df[\"srch_co\"].dt, prop)\n",
    "\n",
    "# ad some more time variables\n",
    "    props[\"stay_span_hours\"] = (df[\"srch_co\"] - df[\"srch_ci\"]).astype('timedelta64[h]')\n",
    "    props[\"stay_span_days\"] = (df[\"srch_co\"] - df[\"srch_ci\"]).astype('timedelta64[D]')\n",
    "        \n",
    "    ret = pd.DataFrame(props)\n",
    "\n",
    "# ad the PCA variables on the ret previously props dataframe\n",
    "    ret = ret.join(dest_small, on=\"srch_destination_id\", how='left', rsuffix=\"dest\")\n",
    "    ret = ret.drop(\"srch_destination_iddest\", axis=1)\n",
    "    return ret\n",
    "\n",
    "# prepare the features\n",
    "sample_train = calc_fast_features(sample_train)  \n",
    "sample_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.head of 2835        168\n",
       "2836         96\n",
       "2837         96\n",
       "2838         96\n",
       "2839        336\n",
       "2840        336\n",
       "3829         72\n",
       "3830         72\n",
       "3831         72\n",
       "3832         72\n",
       "3833         72\n",
       "3834         72\n",
       "3835         72\n",
       "3836         96\n",
       "3837         96\n",
       "3838         96\n",
       "3839         96\n",
       "3840         72\n",
       "3841         72\n",
       "3842         48\n",
       "3843         96\n",
       "3844         72\n",
       "3845         72\n",
       "3846         96\n",
       "3847         72\n",
       "3848         72\n",
       "3849         72\n",
       "3850         72\n",
       "3851         72\n",
       "3852         72\n",
       "           ... \n",
       "37664614     96\n",
       "37664615     96\n",
       "37664616     96\n",
       "37664617     96\n",
       "37664618     48\n",
       "37664619     96\n",
       "37664620     72\n",
       "37664621     48\n",
       "37664622     72\n",
       "37664623     96\n",
       "37664624     72\n",
       "37664625     48\n",
       "37664626     48\n",
       "37664627     48\n",
       "37664628     72\n",
       "37664629     72\n",
       "37664630     72\n",
       "37664631     72\n",
       "37666462     72\n",
       "37666463     72\n",
       "37666464     72\n",
       "37666465     72\n",
       "37666466     24\n",
       "37666467     24\n",
       "37668467    120\n",
       "37668468    240\n",
       "37668469    240\n",
       "37668470    144\n",
       "37668471    144\n",
       "37668472    144\n",
       "Name: stay_span_hours, dtype: float64>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the file\n",
    "#sample_train['stay_span_hours'].head\n",
    "#sample_train.to_csv('preparation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Handling of missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first attemp just fill missing value with -1\n",
    "sample_train.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Check the most important features with randomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) hotel_continent                0.292153\n",
      " 2) hotel_market                   0.161655\n",
      " 3) hotel_country                  0.142039\n",
      " 4) 0                              0.076820\n",
      " 5) is_package                     0.061221\n",
      " 6) srch_destination_id            0.058125\n",
      " 7) stay_span_hours                0.047409\n",
      " 8) stay_span_days                 0.037203\n",
      " 9) 2                              0.031167\n",
      "10) orig_destination_distance      0.024796\n",
      "11) site_name                      0.013378\n",
      "12) user_location_country          0.011775\n",
      "13) posa_continent                 0.011198\n",
      "14) 1                              0.010763\n",
      "15) user_location_region           0.008694\n",
      "16) srch_destination_type_id       0.006436\n",
      "17) nb_person                      0.001258\n",
      "18) ci_month                       0.000657\n",
      "19) co_dayofweek                   0.000638\n",
      "20) year                           0.000593\n",
      "21) srch_adults_cnt                0.000520\n",
      "22) co_quarter                     0.000495\n",
      "23) user_location_city             0.000387\n",
      "24) month                          0.000299\n",
      "25) co_month                       0.000275\n",
      "26) day                            0.000045\n",
      "27) ci_dayofweek                   0.000000\n",
      "28) ci_quarter                     0.000000\n",
      "29) cnt                            0.000000\n",
      "30) co_day                         0.000000\n",
      "31) ci_day                         0.000000\n",
      "32) minute                         0.000000\n",
      "33) dayofweek                      0.000000\n",
      "34) hour                           0.000000\n",
      "35) is_booking                     0.000000\n",
      "36) is_mobile                      0.000000\n",
      "37) quarter                        0.000000\n",
      "38) srch_children_cnt              0.000000\n",
      "39) srch_rm_cnt                    0.000000\n",
      "40) channel                        0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# initialize the forest\n",
    "forest = RandomForestClassifier(n_estimators=50,min_weight_fraction_leaf=0.1,n_jobs = -1)\n",
    "\n",
    "\n",
    "# consider the useful variables.Exclude family for the moment need to make it categorical\n",
    "features_column = [c for c in sample_train.columns if c not in [\"hotel_cluster\",\"user_id\",\"family\"]]\n",
    "X_train = sample_train[features_column]\n",
    "Y_train = sample_train[\"hotel_cluster\"]\n",
    "\n",
    "# fit the forest\n",
    "forest.fit(X_train,Y_train)\n",
    "\n",
    "# analyse important features\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, \n",
    "                            features_column[indices[f]], \n",
    "                            importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ml-metrics\n",
      "Requirement already satisfied (use --upgrade to upgrade): pandas in /Users/jpmallette/anaconda/lib/python2.7/site-packages (from ml-metrics)\n",
      "Requirement already satisfied (use --upgrade to upgrade): numpy in /Users/jpmallette/anaconda/lib/python2.7/site-packages (from ml-metrics)\n",
      "Requirement already satisfied (use --upgrade to upgrade): python-dateutil in /Users/jpmallette/anaconda/lib/python2.7/site-packages (from pandas->ml-metrics)\n",
      "Requirement already satisfied (use --upgrade to upgrade): pytz>=2011k in /Users/jpmallette/anaconda/lib/python2.7/site-packages (from pandas->ml-metrics)\n",
      "Requirement already satisfied (use --upgrade to upgrade): six>=1.5 in /Users/jpmallette/anaconda/lib/python2.7/site-packages/six-1.10.0-py2.7.egg (from python-dateutil->pandas->ml-metrics)\n",
      "Installing collected packages: ml-metrics\n",
      "Successfully installed ml-metrics-0.1.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 8.0.3, however version 8.1.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#  Annexe\n",
    "# properly install ipython package\n",
    "import pip\n",
    "\n",
    "def install(package):\n",
    "   pip.main(['install', package])\n",
    "\n",
    "install('ml_metrics') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
