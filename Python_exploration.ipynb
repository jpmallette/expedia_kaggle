{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we want to do is read in the data, explore, take a sample and create new variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialisation and read the data\n",
    "# https://www.dataquest.io/blog/kaggle-tutorial/\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "os.chdir('/Users/jpmallette/Desktop/kaggle_expedia/')\n",
    "\n",
    "destinations = pd.read_csv(\"destinations.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create some variables useful for downsampling \n",
    "train[\"date_time\"] = pd.to_datetime(train[\"date_time\"])\n",
    "train[\"year\"] = train[\"date_time\"].dt.year\n",
    "train[\"month\"] = train[\"date_time\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37670293, 24)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick validation\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# draw sampling base on the number of user\n",
    "def draw_sample(df,row):\n",
    "\n",
    "    unique_users = train.user_id.unique()\n",
    "\n",
    "    sel_user_ids = [unique_users[i] for i in sorted(random.sample(range(len(unique_users)), row)) ]\n",
    "    sel_train = train[train.user_id.isin(sel_user_ids)]\n",
    "\n",
    "    sample_train = sel_train[((sel_train.year == 2013) | ((sel_train.year == 2014) & (sel_train.month < 8)))]\n",
    "    sample_test = sel_train[((sel_train.year == 2014) & (sel_train.month >= 8))]\n",
    "\n",
    "    # remove click events\n",
    "    sample_test = sample_test[sample_test.is_booking == True]\n",
    "    \n",
    "    # remove \n",
    "    return sample_train,sample_test\n",
    "\n",
    "# draw the sample\n",
    "sample_train, sample_test = draw_sample(train,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Create new variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>couple</th>\n",
       "      <td>98235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>33646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monoparental_with_kids</th>\n",
       "      <td>7083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>25867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single</th>\n",
       "      <td>37771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count\n",
       "family                       \n",
       "couple                  98235\n",
       "family                  33646\n",
       "group                     153\n",
       "monoparental_with_kids   7083\n",
       "other                   25867\n",
       "single                  37771"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of people in trip categorisation\n",
    "sample_train[\"nb_person\"] =  sample_train['srch_adults_cnt'] + sample_train['srch_children_cnt']\n",
    "\n",
    "# family variables\n",
    "sample_train['family'] = 'group'\n",
    "\n",
    "sample_train.ix[(sample_train.srch_adults_cnt == 1) & \n",
    "                (sample_train.srch_children_cnt == 0),'family'] = 'single'\n",
    "\n",
    "sample_train.ix[(sample_train.srch_adults_cnt == 1) & \n",
    "                (sample_train.srch_children_cnt > 0),'family'] = 'monoparental_with_kids'\n",
    "\n",
    "sample_train.ix[(sample_train.srch_adults_cnt == 2) & \n",
    "                (sample_train.srch_children_cnt == 0),'family'] = 'couple'\n",
    "\n",
    "sample_train.ix[(sample_train.srch_adults_cnt == 2) & \n",
    "                (sample_train.srch_children_cnt > 0),'family'] = 'family'\n",
    "\n",
    "sample_train.ix[(sample_train.srch_adults_cnt > 2) & \n",
    "                (sample_train.srch_children_cnt > 4),'family'] = 'group'\n",
    "\n",
    "# We can see the categorisation is not working\n",
    "sample_train.groupby(['family'])['family'].agg(['count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# PCA \n",
    "pca = PCA(n_components=3)\n",
    "dest_small = pca.fit_transform(destinations[[\"d{0}\".format(i + 1) for i in range(149)]])\n",
    "dest_small = pd.DataFrame(dest_small)\n",
    "dest_small[\"srch_destination_id\"] = destinations[\"srch_destination_id\"]\n",
    "\n",
    "# date variables\n",
    "def calc_fast_features(df):\n",
    "    df[\"date_time\"] = pd.to_datetime(df[\"date_time\"])\n",
    "    df[\"srch_ci\"] = pd.to_datetime(df[\"srch_ci\"], format='%Y-%m-%d', errors=\"coerce\")\n",
    "    df[\"srch_co\"] = pd.to_datetime(df[\"srch_co\"], format='%Y-%m-%d', errors=\"coerce\")\n",
    "    \n",
    "    props = {}\n",
    "    for prop in [\"month\", \"day\", \"hour\", \"minute\", \"dayofweek\", \"quarter\"]:\n",
    "        props[prop] = getattr(df[\"date_time\"].dt, prop)\n",
    "    \n",
    "    carryover = [p for p in df.columns if p not in [\"date_time\", \"srch_ci\", \"srch_co\"]]\n",
    "    for prop in carryover:\n",
    "        props[prop] = df[prop]\n",
    "    \n",
    "    date_props = [\"month\", \"day\", \"dayofweek\", \"quarter\"]\n",
    "    for prop in date_props:\n",
    "        props[\"ci_{0}\".format(prop)] = getattr(df[\"srch_ci\"].dt, prop)\n",
    "        props[\"co_{0}\".format(prop)] = getattr(df[\"srch_co\"].dt, prop)\n",
    "    props[\"stay_span\"] = (df[\"srch_co\"] - df[\"srch_ci\"]).astype('timedelta64[h]')\n",
    "        \n",
    "    ret = pd.DataFrame(props)\n",
    "    \n",
    "    ret = ret.join(dest_small, on=\"srch_destination_id\", how='left', rsuffix=\"dest\")\n",
    "    ret = ret.drop(\"srch_destination_iddest\", axis=1)\n",
    "    return ret\n",
    "\n",
    "sample_train = calc_fast_features(sample_train)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the file\n",
    "sample_train.describe \n",
    "sample_train.to_csv('preparation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first attemp just fill missing value with -1\n",
    "sample_train.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Machine Learning predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7396da6b162a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mml_metrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hotel_cluster\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Random Forest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# evaluation for algorithm\n",
    "import ml_metrics as metrics\n",
    "target = [[l] for l in sample_test[\"hotel_cluster\"]]\n",
    "metrics.mapk(target, predictions, k=5)\n",
    "\n",
    "# Random Forest to find the most important features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from itertools import chain\n",
    "\n",
    "all_probs = []\n",
    "unique_clusters = df[\"hotel_cluster\"].unique()\n",
    "for cluster in unique_clusters:\n",
    "    df[\"target\"] = 1\n",
    "    df[\"target\"][df[\"hotel_cluster\"] != cluster] = 0\n",
    "    predictors = [col for col in df if col not in ['hotel_cluster', \"target\"]]\n",
    "    probs = []\n",
    "    cv = KFold(len(df[\"target\"]), n_folds=2)\n",
    "    clf = RandomForestClassifier(n_estimators=10, min_weight_fraction_leaf=0.1)\n",
    "    for i, (tr, te) in enumerate(cv):\n",
    "        clf.fit(df[predictors].iloc[tr], df[\"target\"].iloc[tr])\n",
    "        preds = clf.predict_proba(df[predictors].iloc[te])\n",
    "        probs.append([p[1] for p in preds])\n",
    "    full_probs = chain.from_iterable(probs)\n",
    "    all_probs.append(list(full_probs))\n",
    "\n",
    "prediction_frame = pd.DataFrame(all_probs).T\n",
    "prediction_frame.columns = unique_clusters\n",
    "\n",
    "def find_top_5(row):\n",
    "    return list(row.nlargest(5).index)\n",
    "\n",
    "preds = []\n",
    "for index, row in prediction_frame.iterrows():\n",
    "    preds.append(find_top_5(row))\n",
    "\n",
    "metrics.mapk([[l] for l in t2.iloc[\"hotel_cluster\"]], preds, k=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ml-metrics\n",
      "Requirement already satisfied (use --upgrade to upgrade): pandas in /Users/jpmallette/anaconda/lib/python2.7/site-packages (from ml-metrics)\n",
      "Requirement already satisfied (use --upgrade to upgrade): numpy in /Users/jpmallette/anaconda/lib/python2.7/site-packages (from ml-metrics)\n",
      "Requirement already satisfied (use --upgrade to upgrade): python-dateutil in /Users/jpmallette/anaconda/lib/python2.7/site-packages (from pandas->ml-metrics)\n",
      "Requirement already satisfied (use --upgrade to upgrade): pytz>=2011k in /Users/jpmallette/anaconda/lib/python2.7/site-packages (from pandas->ml-metrics)\n",
      "Requirement already satisfied (use --upgrade to upgrade): six>=1.5 in /Users/jpmallette/anaconda/lib/python2.7/site-packages/six-1.10.0-py2.7.egg (from python-dateutil->pandas->ml-metrics)\n",
      "Installing collected packages: ml-metrics\n",
      "Successfully installed ml-metrics-0.1.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 8.0.3, however version 8.1.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#  Annexe\n",
    "# properly install ipython package\n",
    "import pip\n",
    "\n",
    "def install(package):\n",
    "   pip.main(['install', package])\n",
    "\n",
    "install('ml_metrics') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
